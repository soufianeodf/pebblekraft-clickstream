version: "3.3"
services:
  # Website container
  website:
    build:
      context: ./website
      dockerfile: Dockerfile
    platform: linux/amd64
    image: soufianeodf/website
    container_name: website
    networks:
      - frontend
    deploy:
      replicas: 1
    ports:
      - '80:80'

  # Zookeeper container
  zookeeper:
    image: zookeeper
    networks:
      - backend
    restart: always
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - 2181:2181
    environment:
      ZOO_MY_ID: 1

  # Apache Kafka container
  divolte-kafka:
    image: wurstmeister/kafka
    container_name: divolte-kafka
    networks:
      - backend
    ports:
      - 9092:9092
    environment:
      KAFKA_ADVERTISED_HOST_NAME: divolte-kafka
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_CREATE_TOPICS: "tracking:4:1"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://divolte-kafka:9092,INTERNAL://localhost:9093
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,INTERNAL://0.0.0.0:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

  # Kafka Manager container
  kafka_manager:
    image: hlebalbau/kafka-manager:stable
    container_name: kafka-manager
    restart: always
    deploy:
      replicas: 1
    networks:
      - backend
    ports:
      - "9000:9000"
    environment:
      ZK_HOSTS: "zookeeper:2181"
      APPLICATION_SECRET: "random-secret"
    command: -Dpidfile.path=/dev/null

  # Divolte container
  docker-divolte:
    build:
      context: ./divolte-collector
      dockerfile: Dockerfile
    platform: linux/amd64
    image: soufianeodf/divolte-collector
    container_name: docker-divolte
    networks:
      - frontend
      - backend
    deploy:
      replicas: 1
    restart: always
    environment:
      DIVOLTE_KAFKA_BROKER_LIST: divolte-kafka:9092
      DIVOLTE_KAFKA_TOPIC: tracking-avro
    ports:
      - 8290:8290
    depends_on:
      - divolte-kafka

  # ELK stack
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.1
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - cluster.name=es-my-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - backend
  kibana:
    image: docker.elastic.co/kibana/kibana:7.14.1
    container_name : kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - 5601:5601
    networks:
      - backend
    depends_on:
      - elasticsearch
  logstash:
    image: docker.elastic.co/logstash/logstash:7.14.1
    container_name: logstash
    hostname: logstash
    ports:
      - 9600:9600
      - 8089:8089
    depends_on:
      - elasticsearch
    networks:
      - backend
    volumes:
      - ./logstash_pipeline/:/usr/share/logstash/pipeline
#    links:
#      - elasticsearch:elasticsearch

volumes:
  data01:
    driver: local

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
